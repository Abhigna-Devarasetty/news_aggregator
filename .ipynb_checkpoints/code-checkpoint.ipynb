{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Aggregator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will fill it now, focusing on the code as of now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Installing required packages/ libraries\n",
    "# !pip3 install langchain newsapi-python transformers datasets rouge-score sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datetime import datetime, timedelta\n",
    "from newsapi import NewsApiClient\n",
    "import pandas as pd\n",
    "from langchain.chains import TransformChain, SequentialChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import (\n",
    "    T5Tokenizer, \n",
    "    T5ForConditionalGeneration,\n",
    "    pipeline,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from datasets import load_dataset, Dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "NEWSAPI_KEY = \"2e44f6aa50bc4b6ab70dca723a81186d\"\n",
    "TOPICS = [\"security systems\", \"camera access\", \"voip\", \"broadband\", \"phone services\"]\n",
    "# TOPICS = [\"technology\", \"business\", \"health\", \"politics\", \"sports\", \"science\", \"entertainment\", \"climate change\", \"artificial intelligence\", \"cryptocurrency\"]\n",
    "RELEVANCE_THRESHOLD = 0.01\n",
    "\n",
    "# Initialize NewsAPI\n",
    "newsapi = NewsApiClient(api_key=NEWSAPI_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching Articles from NewsAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching articles from last 3 days from NewsAPI for the topics related to Client\n",
    "def fetch_tech_articles():\n",
    "    end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    start_date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    all_articles = []\n",
    "    for topic in TOPICS:\n",
    "        response = newsapi.get_everything(\n",
    "            q=topic,\n",
    "            from_param=start_date,\n",
    "            to=end_date,\n",
    "            language='en',\n",
    "            sort_by='relevancy',\n",
    "            page_size=100  # Maximum as it is in developer mode\n",
    "        )\n",
    "        all_articles.extend(response['articles'])\n",
    "    \n",
    "    return pd.DataFrame(all_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevance checking for articles fetched from NewsAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot relevance check to check the relevance of the articles fetched from NewsAPI\n",
    "class RelevanceChecker:\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.topic_descriptions = [\n",
    "            \"Technical articles about physical or digital security systems\",\n",
    "            \"News about camera technology and surveillance systems\",\n",
    "            \"Voice over IP services and related technologies\",\n",
    "            \"Broadband internet infrastructure and services\",\n",
    "            \"Mobile phone services and telecommunications\"\n",
    "        ]\n",
    "        self.topic_embeddings = self.model.encode(self.topic_descriptions)\n",
    "    \n",
    "    def is_relevant(self, text, threshold=RELEVANCE_THRESHOLD):\n",
    "        if not text or len(text) < 100:  # Skip short content\n",
    "            return False\n",
    "        text_embedding = self.model.encode([text])\n",
    "        similarity = cosine_similarity(text_embedding, self.topic_embeddings)\n",
    "        return similarity.max() > threshold\n",
    "\n",
    "# Initialize once\n",
    "relevance_checker = RelevanceChecker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_articles(df):\n",
    "    # Clean and deduplicate\n",
    "    df = df.drop_duplicates(subset=['title'])\n",
    "    df = df[df['content'].notna()]\n",
    "    df['content'] = df['content'].str.split('â€¦').str[0].str.strip()\n",
    "    # return df['content']\n",
    "    # Filter relevant articles\n",
    "    df['is_relevant'] = df['content'].apply(relevance_checker.is_relevant)\n",
    "    return df[df['is_relevant']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the T5 models (T5-small, T5-base, distilT5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_summarization_models():\n",
    "    # Load T5-Small\n",
    "    t5_small = pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=\"t5-small\",\n",
    "        device=0 if torch.cuda.is_available() else -1\n",
    "    )\n",
    "    \n",
    "    Load T5-Base\n",
    "    t5_base = pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=\"t5-base\",\n",
    "        device=0 if torch.cuda.is_available() else -1\n",
    "    )\n",
    "    \n",
    "    # Load DistilT5\n",
    "    # distil_t5 = pipeline(\n",
    "    #     \"text2text-generation\",\n",
    "    #     model=\"mrm8488/distilT5-base-finetuned-summarize-news\",\n",
    "    #     device=0 if torch.cuda.is_available() else -1\n",
    "    # )\n",
    "    # distil_t5 = pipeline(\n",
    "    #     \"text2text-generation\", \n",
    "    #     model=\"dropout05/lfom_distilt5_realnewslike\",\n",
    "    #     device=0 if torch.cuda.is_available() else -1)\n",
    "    \n",
    "    return {\n",
    "        \"t5_small\": t5_small,\n",
    "        \"t5_base\": t5_base,\n",
    "        # \"distil_t5\": distil_t5\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_articles(df, models):\n",
    "    results = []\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            summaries = {\n",
    "                \"title\": row[\"title\"],\n",
    "                \"url\": row[\"url\"],\n",
    "                \"published\": row[\"publishedAt\"]\n",
    "            }\n",
    "            for model_name, model in models.items():\n",
    "                summary = model(\n",
    "                    \"summarize: \" + row[\"content\"],\n",
    "                    max_length=150,\n",
    "                    min_length=30,\n",
    "                    truncation=True\n",
    "                )[0]['generated_text']\n",
    "                summaries[model_name] = summary\n",
    "            results.append(summaries)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {row['title']}: {str(e)}\")\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning the model (Optional, not doing it for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(model_name, dataset):\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    def preprocess(examples):\n",
    "        inputs = tokenizer(\"summarize: \" + examples[\"article\"], max_length=512, truncation=True, padding=\"max_length\")\n",
    "        labels = tokenizer(examples[\"summary\"], max_length=150, truncation=True, padding=\"max_length\")\n",
    "        return {\"input_ids\": inputs[\"input_ids\"], \"attention_mask\": inputs[\"attention_mask\"], \"labels\": labels[\"input_ids\"]}\n",
    "\n",
    "    tokenized_data = dataset.map(preprocess, batched=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./{model_name}_fine_tuned\",\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=4,\n",
    "        logging_dir=\"./logs\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_data,\n",
    "    )\n",
    "    trainer.train()\n",
    "    model.save_pretrained(f\"./{model_name}_fine_tuned\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 270 relevant articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries saved to 'tech_news_summaries.csv'.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Fetch and preprocess articles\n",
    "    raw_df = fetch_tech_articles()\n",
    "    preprocessed_df = preprocess_articles(raw_df)\n",
    "    print(f\"Fetched {len(preprocessed_df)} relevant articles.\")\n",
    "\n",
    "    # Step 2: Load summarization models\n",
    "    models = load_summarization_models()\n",
    "\n",
    "    # Step 3: Summarize articles with all models\n",
    "    summaries_df = summarize_articles(preprocessed_df, models)\n",
    "    summaries_df.to_csv(\"tech_news_summaries.csv\", index=False)\n",
    "    print(\"Summaries saved to 'tech_news_summaries.csv'.\")\n",
    "\n",
    "    # Step 4: Fine-tune models (optional, requires GPU)\n",
    "    # Uncomment to fine-tune\n",
    "    # fine_tune_model(\"t5-small\", dataset)\n",
    "    # fine_tune_model(\"t5-base\", dataset)\n",
    "    # fine_tune_model(\"mrm8488/distilT5-base-finetuned-summarize-news\", dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "7500c3e1c7c786e4ba1e4b4eb7588219b4e35d5153674f92eb3a82672b534f6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
